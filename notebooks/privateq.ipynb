{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrivateQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "\n",
    "Import necessary libraries and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up\n",
    "import os\n",
    "import sys; sys.path.append(\"..\")\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv; load_dotenv()\n",
    "\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from privateq.config import ROOT_DIR\n",
    "\n",
    "# Set up ray with credentials and start ray\n",
    "ray.init(runtime_env={\n",
    "    \"env_vars\": {\n",
    "        \"OPENAI_API_BASE\": os.environ[\"OPENAI_API_BASE\"],\n",
    "        \"OPENAI_API_KEY\": os.environ[\"OPENAI_API_KEY\"], \n",
    "    },\n",
    "    \"working_dir\": str(ROOT_DIR)\n",
    "})\n",
    "\n",
    "# Show resources\n",
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Load, sectionalize, chunk and embed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model parameters\n",
    "from privateq.config import EMBEDDING_DIMENSIONS, MAX_CONTENT_LENGTH\n",
    "\n",
    "print(f'EMBEDDING_DIMENSIONS: {EMBEDDING_DIMENSIONS}\\nMAX_CONTENT_LENGTH: {MAX_CONTENT_LENGTH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data using Ray\n",
    "\n",
    "from pathlib import Path\n",
    "from privateq.config import FILE_DIR\n",
    "\n",
    "# Find documents\n",
    "DOCS_DIR = Path(FILE_DIR, os.environ.get(\"DOCS_DIR\"))\n",
    "print(f'DOCS_DIR: {DOCS_DIR}')\n",
    "assert DOCS_DIR.exists(), f'{DOCS_DIR} does not exist.'\n",
    "\n",
    "# Filter out html files and load them as ray dataset\n",
    "ds = ray.data.from_items([{\"path\": path} for path in DOCS_DIR.rglob(\"*.html\") if not path.is_dir()])\n",
    "print(f\"{ds.count()} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data\n",
    "Extract content from dataset, identify sections in html pages and extract text between them. Then save all of them to a list of dictionaries that map text of a section to a specific url with specific anchor id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from privateq.data_process import extract_sections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample extraction process\n",
    "# sample_html_fp = Path(FILE_DIR, \"docs.ray.io/en/master/rllib/rllib-env.html\")\n",
    "# extract_sections({\"path\": sample_html_fp})[0]\n",
    "\n",
    "# Extract sections from dataset\n",
    "sections_ds = ds.flat_map(extract_sections)\n",
    "print(f'Sections Count: {sections_ds.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot section lengths to observe the dataset\n",
    "section_lengths = []\n",
    "for section in sections_ds.take_all():\n",
    "    section_lengths.append(len(section[\"text\"]))\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(section_lengths, marker='x', color='g')\n",
    "plt.title(\"Section Lengths\")\n",
    "plt.ylabel(\"# of characters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk sectionalized data\n",
    "\n",
    "from functools import partial\n",
    "from privateq.data_process import chunk_section\n",
    "\n",
    "chunk_size = 300\n",
    "chunk_overlap = 50\n",
    "\n",
    "# Chunk a sample section\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "#     chunk_size=chunk_size,\n",
    "#     chunk_overlap=chunk_overlap,\n",
    "#     length_function=len)\n",
    "# sample_section = sections_ds.take(1)[0]\n",
    "# chunks = text_splitter.create_documents(\n",
    "#     texts=[sample_section[\"text\"]], \n",
    "#     metadatas=[{\"source\": sample_section[\"source\"]}])\n",
    "# print (chunks[0])\n",
    "\n",
    "# Chunk all data using ray for scalability\n",
    "chunks_ds = sections_ds.flat_map(partial(\n",
    "    chunk_section, \n",
    "    chunk_size=chunk_size, \n",
    "    chunk_overlap=chunk_overlap))\n",
    "print(f\"{chunks_ds.count()} chunks\")\n",
    "chunks_ds.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import embedding libraries\n",
    "from privateq.embed_chunks import EmbedChunks\n",
    "\n",
    "# Embed chunks\n",
    "embedding_model_name = \"thenlper/gte-base\"\n",
    "# Tune gpu number to suit environment\n",
    "embedded_chunks = chunks_ds.map_batches(\n",
    "    EmbedChunks,\n",
    "    fn_constructor_kwargs={\"model_name\": embedding_model_name},\n",
    "    batch_size=100, \n",
    "    num_gpus=1,\n",
    "    concurrency=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample one to check\n",
    "sample = embedded_chunks.take(1)\n",
    "print (\"embedding size:\", len(sample[0][\"embeddings\"]))\n",
    "print (sample[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutdown Ray to clean resources\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
